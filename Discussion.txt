

1. Audio Segment embedding -> 
    1. MFCC 
    2. X vectors -> Best for speaker diarization
    3. D vectors 

2. CLustering -> 
    1. Best for now is to try AHC -> Agglomerative Hiearchical Clustering. 
    2. DBSCAN not really 
    3. K Means -> If we have the value of number of speakers. (if the original approach doesn't work)
    
3. Visualize the clusters. See how well it works 

4. 



There is another apporach that is just fully supervised speaker diarization. Apparently leaving everything to a pretrained model. 
-> Not our aim. 


Possible Challenges -> 

1. When the partitioned audio segment contains multiple speakers -> Confuses the cluster -> so called "Overlap Segments"
2. Try first with AHC -> Agglomerative Hiearchical Clustering 
3. IF time and bad performance ( High DER rate then) try to implement Spectral Clustering or something called VB HMM 

[Wrong approach but still]
4. -> Maybe passing the final transcript through a final LLM to try and fix any errors in audio segmentation ( Stuff that don't make sense )

Datasets for me -> 

1. VoxConverse ->  Ideal target 
2. AMI Meeting Corpus 

