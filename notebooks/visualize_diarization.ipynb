{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Speaker Diarization Results\n",
    "\n",
    "This notebook demonstrates how to visualize and analyze the speaker diarization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.patches as mpatches\n",
    "import IPython.display as ipd\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Add parent directory to path to import project modules\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.data_utils.audio_processor import AudioProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Audio and Diarization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these paths to your files\n",
    "AUDIO_FILE = \"../data/input/example.wav\"  # Path to input audio file\n",
    "DIARIZATION_JSON = \"../data/output/example_diarization.json\"  # Path to diarization JSON result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio file\n",
    "audio_processor = AudioProcessor()\n",
    "audio, sr = audio_processor.load_audio(AUDIO_FILE)\n",
    "\n",
    "# Display audio player\n",
    "print(f\"Audio duration: {len(audio)/sr:.2f} seconds\")\n",
    "ipd.display(ipd.Audio(audio, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diarization results\n",
    "with open(DIARIZATION_JSON, 'r') as f:\n",
    "    diarization_results = json.load(f)\n",
    "\n",
    "# Extract speaker segments\n",
    "speaker_segments = diarization_results[\"speaker_segments\"]\n",
    "transcribed_segments = diarization_results[\"transcribed_segments\"]\n",
    "\n",
    "# Print number of speakers\n",
    "print(f\"Number of speakers detected: {len(speaker_segments)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Speaker Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_diarization(audio, sr, speaker_segments, figsize=(15, 8)):\n",
    "    \"\"\"Visualize diarization results with waveform and speaker segments.\"\"\"\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, gridspec_kw={'height_ratios': [1, 3]})\n",
    "    \n",
    "    # Plot waveform in the first subplot\n",
    "    librosa.display.waveshow(audio, sr=sr, ax=ax1)\n",
    "    ax1.set_title('Waveform')\n",
    "    ax1.set_xlabel('')\n",
    "    \n",
    "    # Plot speaker segments in the second subplot\n",
    "    ax2.set_title('Speaker Diarization')\n",
    "    ax2.set_xlabel('Time (seconds)')\n",
    "    ax2.set_ylabel('Speaker')\n",
    "    \n",
    "    # Set y-axis limits and hide ticks\n",
    "    ax2.set_ylim(0, len(speaker_segments) + 1)\n",
    "    ax2.set_yticks(range(1, len(speaker_segments) + 1))\n",
    "    ax2.set_yticklabels([f'Speaker {i}' for i in speaker_segments.keys()])\n",
    "    \n",
    "    # Set x-axis limits to match the audio duration\n",
    "    duration = len(audio) / sr\n",
    "    ax1.set_xlim(0, duration)\n",
    "    ax2.set_xlim(0, duration)\n",
    "    \n",
    "    # Define colors for each speaker\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    colors = [cmap(i) for i in range(len(speaker_segments))]\n",
    "    \n",
    "    # Plot each speaker's segments\n",
    "    legend_patches = []\n",
    "    for i, (speaker_id, segments) in enumerate(speaker_segments.items()):\n",
    "        for segment in segments:\n",
    "            start = segment['start']\n",
    "            end = segment['end']\n",
    "            rect = mpatches.Rectangle((start, i+0.5), end-start, 0.8, \n",
    "                                       edgecolor='none', facecolor=colors[i], alpha=0.8)\n",
    "            ax2.add_patch(rect)\n",
    "        \n",
    "        legend_patches.append(mpatches.Patch(color=colors[i], label=f'Speaker {speaker_id}'))\n",
    "    \n",
    "    # Add legend\n",
    "    ax2.legend(handles=legend_patches, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, (ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the diarization results\n",
    "fig, _ = visualize_diarization(audio, sr, speaker_segments)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Transcriptions by Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_transcript(transcribed_segments):\n",
    "    \"\"\"Display transcript with timestamps and speaker IDs.\"\"\"\n",
    "    # Sort segments by start time\n",
    "    sorted_segments = sorted(transcribed_segments, key=lambda x: x[\"start\"])\n",
    "    \n",
    "    # Display each segment\n",
    "    for segment in sorted_segments:\n",
    "        start = segment[\"start\"]\n",
    "        end = segment[\"end\"]\n",
    "        speaker_id = segment[\"speaker_id\"]\n",
    "        text = segment[\"text\"]\n",
    "        \n",
    "        # Format: [MM:SS.ms -> MM:SS.ms] Speaker X: Text\n",
    "        start_str = f\"{int(start // 60):02d}:{start % 60:06.3f}\"\n",
    "        end_str = f\"{int(end // 60):02d}:{end % 60:06.3f}\"\n",
    "        print(f\"[{start_str} -> {end_str}] Speaker {speaker_id}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the transcript\n",
    "display_transcript(transcribed_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listen to Individual Speaker Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_speaker_audio(audio, sr, speaker_segments, speaker_id):\n",
    "    \"\"\"Extract audio segments for a specific speaker.\"\"\"\n",
    "    if speaker_id not in speaker_segments:\n",
    "        print(f\"Speaker {speaker_id} not found in the diarization results.\")\n",
    "        return None\n",
    "    \n",
    "    # Create a silent audio of the same length as the original\n",
    "    speaker_audio = np.zeros_like(audio)\n",
    "    \n",
    "    # Fill in the segments for the specified speaker\n",
    "    for segment in speaker_segments[speaker_id]:\n",
    "        start_sample = int(segment['start'] * sr)\n",
    "        end_sample = int(segment['end'] * sr)\n",
    "        \n",
    "        # Ensure indices are within bounds\n",
    "        start_sample = max(0, start_sample)\n",
    "        end_sample = min(len(audio), end_sample)\n",
    "        \n",
    "        if end_sample > start_sample:\n",
    "            speaker_audio[start_sample:end_sample] = audio[start_sample:end_sample]\n",
    "    \n",
    "    return speaker_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and play audio for each speaker\n",
    "for speaker_id in speaker_segments.keys():\n",
    "    print(f\"Speaker {speaker_id}:\")\n",
    "    speaker_audio = extract_speaker_audio(audio, sr, speaker_segments, speaker_id)\n",
    "    if speaker_audio is not None:\n",
    "        ipd.display(ipd.Audio(speaker_audio, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Speaker Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speaker_statistics(speaker_segments):\n",
    "    \"\"\"Calculate statistics for each speaker.\"\"\"\n",
    "    stats = {}\n",
    "    \n",
    "    for speaker_id, segments in speaker_segments.items():\n",
    "        # Calculate total speaking time\n",
    "        total_duration = sum(seg['end'] - seg['start'] for seg in segments)\n",
    "        \n",
    "        # Count number of turns\n",
    "        num_turns = len(segments)\n",
    "        \n",
    "        # Average turn duration\n",
    "        avg_turn_duration = total_duration / num_turns if num_turns > 0 else 0\n",
    "        \n",
    "        stats[speaker_id] = {\n",
    "            'total_duration': total_duration,\n",
    "            'num_turns': num_turns,\n",
    "            'avg_turn_duration': avg_turn_duration\n",
    "        }\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze speaker statistics\n",
    "stats = speaker_statistics(speaker_segments)\n",
    "\n",
    "# Display statistics\n",
    "print(\"Speaker Statistics:\")\n",
    "print(f\"{'Speaker ID':<15} {'Total Time (s)':<20} {'Number of Turns':<20} {'Avg Turn Duration (s)':<20}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for speaker_id, speaker_stats in stats.items():\n",
    "    print(f\"{speaker_id:<15} {speaker_stats['total_duration']:<20.2f} {speaker_stats['num_turns']:<20} {speaker_stats['avg_turn_duration']:<20.2f}\")\n",
    "\n",
    "# Plot speaking time distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(stats.keys(), [s['total_duration'] for s in stats.values()])\n",
    "plt.title('Speaking Time Distribution')\n",
    "plt.xlabel('Speaker ID')\n",
    "plt.ylabel('Speaking Time (seconds)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
